<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>OpenCV Image Recognition</title>
    <script async src="opencv.js" type="text/javascript"></script>
    <style></style>
  </head>
  <body>
    <canvas id="outputCanvas" width="640" height="480"></canvas>
    <script>
      class FrameData {
        constructor(imageData) {
          this.imageData = imageData;
          this.srcMat = cv.matFromImageData(imageData);
          this.grayMat = new cv.Mat();
          cv.cvtColor(this.srcMat, this.grayMat, cv.COLOR_BGRA2GRAY);
          this.keypoints = new cv.KeyPointVector();
          this.descriptors = new cv.Mat();
          this.goodMatches = new cv.DMatchVector();
          this.transformationMatrix = null;
        }
      }

      class ARFeatureMatcher {
        constructor(
          canvas,
          referenceImageUrl,
          overlayImagePath,
          showMatching = false
        ) {
          this.canvas = canvas;
          this.context = canvas.getContext("2d", { willReadFrequently: true });
          this.referenceImageUrl = referenceImageUrl;
          this.overlayImagePath = overlayImagePath; // Changed to reflect PNG path
          this.isOpenCVInitialized = false;
          this.showMatching = showMatching;
          this.frameQueue = [];
          this.processing = false;
          this.imageCapture = null;
          this.overlayPNGs = []; // To store the preloaded PNGs
          this.currentFrameIndex = 0; // To track which PNG to display
        }

        async initialize() {
          try {
            await this.initializeOpenCV();
            console.log("OpenCV Initialized");
            await this.setupCVDependentProperties();
            console.log("OpenCV Properties Initialized");
            await this.initializeCamera();
            console.log("Camera Initialized");
            await this.loadReferenceImage(this.referenceImageUrl);
            console.log("Reference Image Loaded");
            await this.loadOverlayPNGs(); // Replacing video loading with PNG sequence loading
            console.log("Overlay PNGs Loaded");
            this.startProcessing();
            console.log("Started Processing");
          } catch (err) {
            console.error("Initialization error: ", err);
          }
        }

        initializeOpenCV() {
          return new Promise((resolve, reject) => {
            try {
              if (typeof cv === "undefined") {
                alert("OpenCV.js not loaded");
                reject("OpenCV.js not loaded");
                return;
              }

              // Check if OpenCV is already initialized
              if (cv["onRuntimeInitialized"]) {
                alert("OpenCV.js already loaded");
                this.isOpenCVInitialized = true;
                resolve();
              } else {
                // Set up the callback for when OpenCV initializes
                cv["onRuntimeInitialized"] = () => {
                  alert("OpenCV.js successfully loaded");
                  this.isOpenCVInitialized = true;
                  resolve();
                };

                // In case the script is already loaded but `onRuntimeInitialized` has already fired
                if (cv.Mat) {
                  alert("OpenCV.js already initialized (fallback)");
                  this.isOpenCVInitialized = true;
                  resolve();
                }
              }
            } catch (err) {
              alert("initializeOpenCV inner error: " + err);
              console.error("initializeOpenCV inner error: ", err);
              reject(err);
            }
          }).catch((err) => {
            alert("initializeOpenCV outer error: " + err);
            console.error("initializeOpenCV outer error: ", err);
          });
        }

        async setupCVDependentProperties() {
          try {
            if (this.isOpenCVInitialized) {
              this.featureDetector = new cv.AKAZE();
              this.featureDetector.setThreshold(0.001);
              this.matcher = new cv.BFMatcher();
            } else {
              console.error(
                "setupCVDependentProperties error: OpenCV not initialized."
              );
            }
          } catch (err) {
            console.error("setupCVDependentProperties error: ", err);
          }
        }

        async initializeCamera() {
          try {
            const stream = await navigator.mediaDevices.getUserMedia({
              video: { facingMode: "environment" },
            });

            this.video = document.createElement("video");
            this.video.setAttribute("playsinline", "true");
            this.video.muted = true;
            this.video.style.display = "none";
            document.body.appendChild(this.video);

            this.video.srcObject = stream;

            this.video.onloadedmetadata = () => {
              // Get the aspect ratio of the video feed
              const aspectRatio =
                this.video.videoWidth / this.video.videoHeight;

              // Set the canvas size while maintaining the aspect ratio
              const desiredWidth = 640; // Set a desired width for the canvas
              this.canvas.width = desiredWidth;
              this.canvas.height = desiredWidth / aspectRatio;

              console.log(
                `Camera initialized with dimensions: ${this.video.videoWidth}x${this.video.videoHeight}`
              );
              console.log(
                `Canvas initialized with dimensions: ${this.canvas.width}x${this.canvas.height}`
              );
            };

            this.video.onerror = (error) => {
              console.error("Video error: ", error);
              this.stopProcessing();
            };

            await this.video.play();
          } catch (err) {
            console.error("initializeCamera error: ", err);
          }
        }

        async loadReferenceImage(url) {
          try {
            console.log("Loading reference image from URL: ", url);

            let img = new Image();
            img.crossOrigin = "anonymous"; // Ensure this is set before src

            img.src = url;
            console.log("CrossOrigin set, and image source assigned.");

            await new Promise((resolve, reject) => {
              img.onload = () => {
                try {
                  let tempMat = cv.imread(img);
                  console.log("Image successfully read into OpenCV.");

                  cv.cvtColor(tempMat, tempMat, cv.COLOR_BGRA2GRAY);
                  this.referenceMat = tempMat;
                  this.referenceKeypoints = new cv.KeyPointVector();
                  this.referenceDescriptors = new cv.Mat();

                  this.featureDetector.detectAndCompute(
                    tempMat,
                    new cv.Mat(),
                    this.referenceKeypoints,
                    this.referenceDescriptors
                  );
                  if (this.referenceDescriptors.empty()) {
                    console.warn(
                      "Reference descriptors are empty after initialization."
                    );
                  } else {
                    console.log("Features detected successfully.");
                  }
                  resolve();
                } catch (err) {
                  console.error(
                    "Error processing reference image in OpenCV: ",
                    err
                  );
                  reject(err);
                }
              };

              img.onerror = (err) => {
                console.error("Error loading reference image: ", err);
                reject(err);
              };
            });
          } catch (err) {
            console.error("loadReferenceImage method error: ", err);
          }
        }

        async loadOverlayPNGs() {
          try {
            console.log("Loading overlay PNG sequence");

            let numFrames = 10; // Example: total number of PNG frames
            for (let i = 1; i <= numFrames; i++) {
              let img = new Image();
              img.src = `${this.overlayImagePath}/PNG_${String(i).padStart(
                4,
                "0"
              )}.png`;
              await new Promise((resolve, reject) => {
                img.onload = () => {
                  this.overlayPNGs.push(img);
                  resolve();
                };
                img.onerror = (err) => reject(err);
              });
            }
            this.currentFrameIndex = 0; // Ensure the index starts at the first frame
            console.log("All PNGs successfully loaded for animation.");
          } catch (err) {
            console.error("loadOverlayPNGs method error: ", err);
          }
        }

        startProcessing() {
          const processFrame = async () => {
            await this.captureAndProcessFrame();
            requestAnimationFrame(processFrame); // Ensures smooth frame rate
          };
          requestAnimationFrame(processFrame); // Starts the loop
        }

        async processQueue() {
          try {
            while (this.frameQueue.length > 0) {
              const frameData = this.frameQueue.shift();
              await this.detectFeaturesAndMatch(frameData);
              if (this.showMatching) {
                //this.visualizeMatches(frameData);
              }
              if (frameData.goodMatches.size() > 0) {
                this.calculateTransformationAndOverlay(frameData);
              }
            }
          } catch (err) {
            console.error("processQueue: ", err);
          }
        }

        /*visualizeMatches(frameData) {
          try {
            let imgMatches = new cv.Mat();
            cv.drawMatches(
              frameData.srcMat,
              frameData.keypoints,
              this.referenceMat,
              this.referenceKeypoints,
              frameData.goodMatches,
              imgMatches
            );
            cv.imshow("outputCanvas", imgMatches);
            imgMatches.delete();
          } catch (err) {
            console.error("visualizeMatches error: ", err);
          }
        }*/

        filterMatches(matches, distanceThreshold = 0.9) {
          try {
            let goodMatches = new cv.DMatchVector();
            for (let i = 0; i < matches.size(); ++i) {
              let match = matches.get(i);
              let dMatch1 = match.get(0);
              let dMatch2 = match.get(1);
              if (
                dMatch1.distance <=
                dMatch2.distance * parseFloat(distanceThreshold)
              ) {
                goodMatches.push_back(dMatch1);
              }
            }
            return goodMatches;
          } catch (err) {
            console.error("filterMatches error: ", err);
          }
        }

        calculateTransformationAndOverlay(frameData) {
          try {
            if (frameData.goodMatches.size() < 5) {
              console.warn(
                "Not enough matches to calculate a robust homography."
              );
              return;
            }

            //console.log("Good matches count:", frameData.goodMatches.size());

            let points1 = [];
            let points2 = [];

            for (let i = 0; i < frameData.goodMatches.size(); i++) {
              let match = frameData.goodMatches.get(i);
              if (
                match.queryIdx >= frameData.keypoints.size() ||
                match.trainIdx >= this.referenceKeypoints.size()
              ) {
                continue;
              }

              points2.push(frameData.keypoints.get(match.queryIdx).pt.x);
              points2.push(frameData.keypoints.get(match.queryIdx).pt.y);
              points1.push(this.referenceKeypoints.get(match.trainIdx).pt.x);
              points1.push(this.referenceKeypoints.get(match.trainIdx).pt.y);
            }

            if (points1.length < 8 || points2.length < 8) {
              console.warn("Not enough valid matches to calculate homography.");
              return;
            }

            let mat1 = new cv.Mat(points1.length / 2, 1, cv.CV_32FC2);
            mat1.data32F.set(points1);

            let mat2 = new cv.Mat(points2.length / 2, 1, cv.CV_32FC2);
            mat2.data32F.set(points2);

            //console.log("Matrices created for homography calculation.");

            let h = cv.findHomography(mat1, mat2, cv.RANSAC);

            if (h.empty()) {
              console.error("Homography matrix is empty");
              mat1.delete();
              mat2.delete();
              return;
            }

            this.applyOverlay(h, frameData);
            mat1.delete();
            mat2.delete();
          } catch (err) {
            console.error("calculateTransformationAndOverlay error: ", err);
          }
        }

        async captureAndProcessFrame() {
          try {
            if (this.processing) return;
            this.processing = true;

            this.context.drawImage(
              this.video,
              0,
              0,
              this.canvas.width,
              this.canvas.height
            );

            let imageData = this.context.getImageData(
              0,
              0,
              this.canvas.width,
              this.canvas.height
            );
            let frameData = new FrameData(imageData);

            try {
              this.frameQueue.push(frameData);
              await this.processQueue();
            } finally {
              frameData.srcMat.delete();
              frameData.grayMat.delete();
              frameData.keypoints.delete();
              frameData.descriptors.delete();
            }

            this.processing = false;
          } catch (err) {
            console.error("captureAndProcessFrame error: ", err);
            this.processing = false;
          }
        }

        async detectFeaturesAndMatch(frameData) {
          if (!this.isOpenCVInitialized) {
            console.warn(
              "detectFeaturesAndMatch error: Initialization incomplete."
            );
            return;
          }
          try {
            this.featureDetector.detectAndCompute(
              frameData.grayMat,
              new cv.Mat(),
              frameData.keypoints,
              frameData.descriptors
            );
            if (
              !this.referenceDescriptors.empty() &&
              !frameData.descriptors.empty()
            ) {
              let matches = new cv.DMatchVectorVector();
              if (this.matcher) {
                this.matcher.knnMatch(
                  frameData.descriptors,
                  this.referenceDescriptors,
                  matches,
                  2
                );
                let goodMatches = this.filterMatches(matches);
                frameData.goodMatches = goodMatches;
              } else {
                console.warn(
                  "detectFeaturesAndMatch error: Matcher not initialized."
                );
              }
            } else {
              console.warn(
                "detectFeaturesAndMatch error: Descriptors are empty."
              );
            }
          } catch (err) {
            console.error("detectFeaturesAndMatch error: ", err);
          }
        }

        applyOverlay(h, frameData) {
          try {
            if (!h.empty()) {
              console.log("Calculating homography and applying overlay.");

              // Get the current overlay PNG frame
              let currentOverlay = this.overlayPNGs[this.currentFrameIndex];

              // Create a temporary canvas to draw the current overlay PNG frame
              let tempCanvas = document.createElement("canvas");
              let tempContext = tempCanvas.getContext("2d");

              // Set the temporary canvas size to match the original PNG size (retain aspect ratio)
              tempCanvas.width = currentOverlay.width;
              tempCanvas.height = currentOverlay.height;

              // Clear the canvas to ensure it's transparent
              tempContext.clearRect(0, 0, tempCanvas.width, tempCanvas.height);

              // Draw the PNG frame onto the tempCanvas
              tempContext.drawImage(
                currentOverlay,
                0,
                0,
                tempCanvas.width,
                tempCanvas.height
              );

              // Convert the tempCanvas to an OpenCV Mat for further processing
              let overlayMat = cv.imread(tempCanvas);

              // Ensure the color channels are in the correct order
              cv.cvtColor(overlayMat, overlayMat, cv.COLOR_RGBA2BGRA);

              // Create a new Mat to store the transformed overlay
              let transformedOverlay = new cv.Mat();

              // Warp the overlay using the homography transformation and fit to marker size
              cv.warpPerspective(
                overlayMat,
                transformedOverlay,
                h,
                new cv.Size(this.canvas.width, this.canvas.height) // Use canvas size to match the final display
              );

              // Split the transformed overlay image into its channels
              let rgbaChannels = new cv.MatVector();
              cv.split(transformedOverlay, rgbaChannels);

              // Extract the alpha channel and normalize it to [0, 1]
              let alpha = new cv.Mat();
              rgbaChannels.get(3).convertTo(alpha, cv.CV_32FC1, 1.0 / 255);

              // Create inverse alpha (1 - alpha) without using cv.ones
              let inverseAlpha = new cv.Mat(
                alpha.rows,
                alpha.cols,
                cv.CV_32FC1
              );
              inverseAlpha.setTo(new cv.Scalar(1.0));
              cv.subtract(inverseAlpha, alpha, inverseAlpha);

              // Convert the B, G, R channels of the overlay to CV_32FC1
              let overlayChannels = new cv.MatVector();
              for (let i = 0; i < 3; i++) {
                let channel = new cv.Mat();
                rgbaChannels.get(i).convertTo(channel, cv.CV_32FC1); // Convert to float for multiplication
                overlayChannels.push_back(channel);
              }

              // Split the frameData.srcMat (video frame) into B, G, R channels
              let backgroundChannels = new cv.MatVector();
              cv.split(frameData.srcMat, backgroundChannels);

              // Convert background channels to CV_32FC1
              for (let i = 0; i < 3; i++) {
                let channel = new cv.Mat();
                backgroundChannels.get(i).convertTo(channel, cv.CV_32FC1); // Convert to float for multiplication
                backgroundChannels.set(i, channel);
              }

              // Perform alpha blending for each channel
              let blendedChannels = new cv.MatVector();
              for (let i = 0; i < 3; i++) {
                let blendedOverlay = new cv.Mat();
                let blendedBackground = new cv.Mat();
                let blendedChannel = new cv.Mat();

                // Multiply overlay channel by alpha
                cv.multiply(overlayChannels.get(i), alpha, blendedOverlay);

                // Multiply background channel by inverse alpha
                cv.multiply(
                  backgroundChannels.get(i),
                  inverseAlpha,
                  blendedBackground
                );

                // Add the two results to get the blended channel
                cv.add(blendedOverlay, blendedBackground, blendedChannel);

                blendedChannels.push_back(blendedChannel);

                // Clean up temporary Mats
                blendedOverlay.delete();
                blendedBackground.delete();
              }

              // Merge blended channels into a single image
              let blendedImage = new cv.Mat();
              cv.merge(blendedChannels, blendedImage);

              // Convert blendedImage to CV_8UC3 (standard 8-bit image)
              blendedImage.convertTo(blendedImage, cv.CV_8UC3);

              // Replace frameData.srcMat with blendedImage
              blendedImage.copyTo(frameData.srcMat);

              // Display the final result on the output canvas
              cv.imshow("outputCanvas", frameData.srcMat);

              // Cleanup
              alpha.delete();
              inverseAlpha.delete();
              for (let i = 0; i < rgbaChannels.size(); i++) {
                rgbaChannels.get(i).delete();
              }
              rgbaChannels.delete();

              for (let i = 0; i < 3; i++) {
                overlayChannels.get(i).delete();
                backgroundChannels.get(i).delete();
                blendedChannels.get(i).delete();
              }
              overlayChannels.delete();
              backgroundChannels.delete();
              blendedChannels.delete();

              blendedImage.delete();
              transformedOverlay.delete();
              overlayMat.delete();

              // Move to the next frame in the PNG sequence for the next iteration
              this.currentFrameIndex =
                (this.currentFrameIndex + 1) % this.overlayPNGs.length;
            }
            h.delete();
          } catch (err) {
            console.error("applyOverlay method error: ", err);
          }
        }
      }

      function getQueryParams() {
        const params = new URLSearchParams(window.location.search);
        return {
          imageBaseName: params.get("image") || "default",
        };
      }
      window.onload = () => {
        try {
          const referenceSrc = "AR_lethal_weapon_marker_500_1000.png";
          const overlayPath = "PNG_animation"; // Folder containing the PNG frames
          const arFeatureMatcher = new ARFeatureMatcher(
            document.getElementById("outputCanvas"),
            referenceSrc,
            overlayPath, // Pass the folder path for PNGs
            true
          );
          arFeatureMatcher.initialize();
        } catch (err) {
          console.error("window.onload error: ", err);
        }
      };

      window.addEventListener("beforeunload", () => {
        cv.destroyAllWindows();
      });
    </script>
  </body>
</html>
